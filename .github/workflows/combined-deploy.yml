# Workflow Name
name: Infrastructure and Application Deploy

# workflow run on:
on:
  push:
    # on pushes to main branch
    branches: [ main ]
    # Only trigger when these paths change
    paths:
      - 'terraform/**'    # in infrastructure code
      - 'app/**'          # in app code
      - 'helm/**'         # in Helm charts
      - '.github/workflows/combined-deploy.yml'  # Changes in workflows

# Environment variables
env:
  AWS_REGION: us-east-1  # AWS region
  TF_VAR_environment: dev  # Terraform environment

# permissions for the GitHub Actions runner
permissions:
  id-token: write    # AWS OIDC authentication
  contents: read     # Needed to checkout code

# List of jobs
jobs:
  # Deploy infrastructure
  terraform:
    runs-on: ubuntu-latest
    steps:
      # Get code from GitHub
      - name: Checkout code
        uses: actions/checkout@v3

      #Using Access Keys
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # Install Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      # Bootstrap Terraform Backend
      - name: Bootstrap Terraform Backend
        working-directory: terraform/bootstrap
        env:
          TF_VAR_aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          TF_VAR_aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          # Check if terraform-lock table exists
          if aws dynamodb describe-table --table-name terraform-lock 2>/dev/null; then
            echo "Bootstrap was already run - skipping..."
          else
            echo "Running bootstrap..."
            terraform init
            terraform apply -auto-approve
          fi
          
          # Get the bucket name and update backend.tf
          BUCKET_NAME=$(terraform output -raw state_bucket_name)
          
          cd ..
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket         = "${BUCKET_NAME}"
              key            = "terraform.tfstate"
              region         = "us-east-1"
              encrypt        = true
              dynamodb_table = "terraform-lock"
            }
          }
          EOF
          
          echo "Updated backend.tf with bucket name: ${BUCKET_NAME}"

      # Configure and initialize backend for main Terraform
      - name: Configure and Init Terraform Backend
        working-directory: terraform
        run: |
          # First verify we have a valid bucket name
          if [ -z "$BUCKET_NAME" ]; then
            echo "Error: No bucket name provided from bootstrap step"
            exit 1
          fi
          
          echo "=== Creating backend.tf ==="
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket         = "$BUCKET_NAME"
              key            = "terraform.tfstate"
              region         = "us-east-1"
              encrypt        = true
              dynamodb_table = "terraform-lock"
            }
          }
          EOF
          
          echo "=== Current backend.tf content ==="
          cat backend.tf
          
          echo "=== Initializing Terraform with new backend ==="
          terraform init -reconfigure

      # Now verify the backend configuration
      - name: Verify Backend Configuration
        working-directory: terraform
        run: |
          echo "=== Verifying backend access ==="
          terraform state list || echo "No state exists yet (this is expected for first run)"
          
          echo "=== Verifying S3 bucket access ==="
          aws s3 ls "s3://$BUCKET_NAME/" || echo "Bucket is empty (this is expected for first run)"

      # Terraform apply main infrastructure
      - name: Apply main Infrastructure
        working-directory: terraform
        run: terraform apply -auto-approve
        env:
          TF_VAR_aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          TF_VAR_aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

  # Build and deploy app
  deploy-app:
    needs: terraform  # Wait for infrastructure to complete
    runs-on: ubuntu-latest  
    steps:
      # Get code from GitHub
      - name: Checkout code
        uses: actions/checkout@v3

      # Set up AWS credentials using access keys
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
        env:
          TF_VAR_aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          TF_VAR_aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      # Log in to ECR
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      # Build and push Docker image
      - name: Build and push Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}  # ECR registry URL
          ECR_REPOSITORY: ly-flask-app-repo                      # repo name
          IMAGE_TAG: ${{ github.sha }}                          # Use commit SHA as tag
        run: |
          cd app
          # Build image with commit SHA tag
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          # Push image with commit SHA tag
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          # Also tag as latest
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          # Push latest tag
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest

      # Deploy to EKS using Helm
      - name: Deploy to EKS
        run: |
          # Update kubeconfig for EKS cluster access
          aws eks update-kubeconfig --name lawyal-project-eks-cluster --region ${{ env.AWS_REGION }}
          
          cd helm
          # Get ECR repository URL
          ECR_REPO=$(aws ecr describe-repositories --repository-names ly-flask-app-repo --query 'repositories[0].repositoryUri' --output text)
          
          # Deploy/upgrade using Helm
          helm upgrade --install flask-app ./flask-app \
            --set image.repository=$ECR_REPO \
            --set image.tag=${{ github.sha }} \
            --wait --timeout 5m

      # Create summary with access information
      - name: Create Deployment Summary
        run: |
          APP_URL=$(kubectl get svc flask-app-flask-app -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
          
          echo ""
          echo "=== ğŸš€ Deployment Complete! ==="
          echo ""
          echo "ğŸ“± Application URL: http://$APP_URL"
          echo ""
          echo "ğŸ“Š Monitoring Information:"
          echo "- CloudWatch Dashboard: https://${AWS_REGION}.console.aws.amazon.com/cloudwatch/home?region=${AWS_REGION}#dashboards:name=EKS-Monitoring-Dashboard"
          echo ""
          echo "ğŸ” Useful Commands:"
          echo "- Check application pods: kubectl get pods"
          echo "- View app logs: kubectl logs -l app=flask-app"
          echo ""

      # Verify endpoints
      - name: Verify Endpoints
        run: |
          echo "Verifying endpoints are responding..."
          
          APP_URL=$(kubectl get svc flask-app-flask-app -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
          
          # Wait for DNS propagation and services to be ready
          sleep 30
          
          # Check if endpoint is responding
          curl -f -s -o /dev/null "http://$APP_URL" || echo "âš ï¸ Warning: Application endpoint not responding yet"
