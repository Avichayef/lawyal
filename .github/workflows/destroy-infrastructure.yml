name: Destroy Infrastructure

on:
  workflow_dispatch:
    inputs:
      confirm_destroy:
        description: 'Type "DESTROY" to confirm infrastructure destruction'
        required: true
        type: string

env:
  AWS_REGION: us-east-1
  TF_VAR_environment: dev

permissions:
  id-token: write
  contents: read

jobs:
  destroy:
    runs-on: ubuntu-latest
    if: github.event.inputs.confirm_destroy == 'DESTROY'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      # Step 1: Find existing state bucket
      - name: Find State Bucket
        id: find-bucket
        run: |
          BUCKET_NAME=$(aws s3 ls | grep lawyal-terraform-state | awk '{print $3}')
          if [ -z "$BUCKET_NAME" ]; then
            echo "Error: Could not find terraform state bucket"
            exit 1
          fi
          echo "bucket_name=${BUCKET_NAME}" >> $GITHUB_OUTPUT
          
          # Update backend.tf with correct bucket name
          cat > terraform/backend.tf << EOF
          terraform {
            backend "s3" {
              bucket         = "${BUCKET_NAME}"
              key            = "terraform.tfstate"
              region         = "us-east-1"
              encrypt        = true
              dynamodb_table = "terraform-lock"
            }
          }
          EOF

      # Step 2: Configure kubectl and get cluster info
      - name: Configure kubectl
        run: |
          CLUSTER_NAME=$(aws eks list-clusters --query 'clusters[0]' --output text)
          if [ ! -z "$CLUSTER_NAME" ]; then
            aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}
            echo "cluster_name=${CLUSTER_NAME}" >> $GITHUB_OUTPUT
          fi

      # Step 3: Remove Helm deployments
      - name: Remove Helm Deployments
        run: |
          if kubectl get ns monitoring &>/dev/null; then
            echo "Removing monitoring stack..."
            helm uninstall monitoring -n monitoring || true
          fi
          
          echo "Removing application..."
          helm uninstall flask-app || true
          helm uninstall monitoring -n monitoring || true
          helm uninstall aws-load-balancer-controller -n kube-system || true
          
          echo "Waiting for resources to be cleaned up..."
          sleep 30

      # Step 4: Destroy main infrastructure
      - name: Destroy Main Infrastructure
        working-directory: terraform
        run: |
          echo "Destroying main infrastructure..."
          terraform init
          terraform destroy -auto-approve
        env:
          TF_VAR_aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          TF_VAR_aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      # Step 5: Destroy bootstrap infrastructure
      - name: Destroy Bootstrap Infrastructure
        working-directory: terraform/bootstrap
        run: |
          echo "Destroying bootstrap infrastructure..."
          # Create provider configuration for bootstrap
          cat > provider.tf << EOF
          provider "aws" {
            region = "us-east-1"
          }
          EOF
          
          terraform init
          terraform destroy -auto-approve \
            -var="aws_access_key_id=${{ secrets.AWS_ACCESS_KEY_ID }}" \
            -var="aws_secret_access_key=${{ secrets.AWS_SECRET_ACCESS_KEY }}"

      # Step 6: Clean up S3 bucket
      - name: Clean up S3 bucket
        if: steps.find-bucket.outputs.bucket_name != ''
        run: |
          echo "Checking if state bucket still exists..."
          if aws s3api head-bucket --bucket ${{ steps.find-bucket.outputs.bucket_name }} 2>/dev/null; then
            echo "Forcing deletion of state bucket..."
            aws s3 rm s3://${{ steps.find-bucket.outputs.bucket_name }} --recursive
            aws s3api delete-bucket --bucket ${{ steps.find-bucket.outputs.bucket_name }}
          fi

      # Step 7: Clean up DynamoDB lock table
      - name: Clean up DynamoDB lock table
        run: |
          echo "Checking if lock table exists..."
          if aws dynamodb describe-table --table-name terraform-lock 2>/dev/null; then
            echo "Deleting lock table..."
            aws dynamodb delete-table --table-name terraform-lock
          fi

      - name: Destruction Complete
        run: |
          echo "âœ… Infrastructure destruction completed successfully"
          echo "The following resources have been destroyed:"
          echo "- Helm deployments (monitoring, flask-app, load balancer controller)"
          echo "- EKS cluster and associated resources"
          echo "- VPC and networking components"
          echo "- IAM roles and policies"
          echo "- ECR repositories"
          echo "- S3 state bucket: ${{ steps.find-bucket.outputs.bucket_name }}"
          echo "- DynamoDB lock table"
